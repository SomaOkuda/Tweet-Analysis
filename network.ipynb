{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomaOkuda/Tweet-Analysis/blob/main/network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okdJcn--ngzf"
      },
      "source": [
        "!pip install janome\n",
        "#MeCabインストール\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.996.3\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a\n",
        "!pip install emoji\n",
        "!pip install japanize-matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUhkppBGqJXh"
      },
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import community\n",
        "import copy\n",
        "import random\n",
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "from networkx.algorithms.community.centrality import girvan_newman\n",
        "import MeCab\n",
        "from janome.tokenizer import Tokenizer\n",
        "tagger=MeCab.Tagger('-Owakati')\n",
        "t = Tokenizer()\n",
        "import re\n",
        "import glob\n",
        "import collections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr_le0oDq4ga"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLMMhCTwjn_D"
      },
      "source": [
        "#csv統合\n",
        "csv_files1 = glob.glob('/content/drive/My Drive/Tweet/tweet/auto_test/*.csv') #jpサンプルツイートフォルダ内結合\n",
        "data_list1 = []\n",
        "for file in csv_files1:\n",
        "  data_list1.append(pd.read_csv(file, lineterminator='\\n'))  \n",
        "df = pd.concat(data_list1, axis=0, sort=False)\n",
        "df = df.drop_duplicates(keep='last') \n",
        "df=df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM5BxRf_GzWn"
      },
      "source": [
        "def Remove_word(list):\n",
        "  rems = ['@', ',', '，', '。', '', ' ', 'http', 'https','//', '、', '×', '.',\n",
        "            '+', '＋', \n",
        "            '/',', ', '(', ')', '（', '）', '://', 'RT', ':', ';','：', '；',\n",
        "            '」','「', '＠', '-', '／',  '%', '％', '!', '！', '#', '＃',\n",
        "            '$', '＄', '=', '＝', 'ー', '￥', '^', '{', '}', '~', '～', \n",
        "            '&', '＆', '・', '?', '??', '？', '？？',  '<', '＜', '>', '＞', '_', '＿', \n",
        "            'co', 'jp', '(@', '○', '『', '』', '”', '’', '\"', '…', \n",
        "            ')」', '〇', '【', '】', '[', ']',\n",
        "            'から', 'より', 'こそ', 'でも', 'しか','さえ', 'けれど', 'たり', 'つつ', 'とも',\n",
        "            'たら', 'ある', 'なら', 'のに', 'です', 'ます', 'する', 'ほど', 'ない', 'くる',\n",
        "            'なり', 'そう', 'まし', 'その', 'この', 'あの', 'せる', 'どう', 'ため', 'どこ',\n",
        "            'いる', 'これ', 'それ', 'あれ', 'いい', 'など', 'あっ', 'もう', 'さん', 'じゃ',\n",
        "            'から', 'あり', 'ので', 'とも', 'ませ', 'でし', 'とき', 'こと', 'なる', 'って',\n",
        "            'ただ', 'まで', 'もの', 'つか', 'なっ', 'でき', 'もっ', 'けど', 'ほぼ', 'なー',\n",
        "            'そこ', 'ここ', 'だろ', 'なん', 'だっ', 'なあ', 'っけ', 'せる', 'やっ', 'また',\n",
        "            'どれ', 'なれ', 'かも', 'いく', 'いけ', 'いう', 'たい', 'あと', 'かも', 'しれ',  \n",
        "            'こう', 'なく', 'よく', 'だけ', 'れる', 'よう', 'かけ', 'どの', 'てる', 'とか',\n",
        "            'という', '思う', '思っ', 'として', 'ところ', 'しまう', 'なんか', 'そんな', \n",
        "            'でしょ', 'しまい', 'わかり', 'まま'\n",
        "            ]\n",
        "  for number in range(10000):\n",
        "    rems.append(str(number))\n",
        "\n",
        "# 一文字のひらがなとカタカナ，全角数字，アルファベット大文字・小文字\n",
        "  hirakana    = [chr(i) for i in range(12353, 12436)]\n",
        "  katakana    = [chr(i) for i in range(12449, 12533)]\n",
        "  zenkaku_num = [chr(i) for i in range(65296, 65296+10)]\n",
        "  alph_L      = [chr(i) for i in range(97, 97+26)]\n",
        "  alph_S      = [chr(i) for i in range(65, 65+26)]\n",
        "\n",
        "  for a in range(len(hirakana)):\n",
        "    rems.append(hirakana[a])\n",
        "  for b in range(len(katakana)):\n",
        "    rems.append(katakana[b])\n",
        "  for c in range(len(zenkaku_num)):\n",
        "    rems.append(zenkaku_num[c])\n",
        "  for d in range(len(alph_L)):\n",
        "    rems.append(alph_L[d])\n",
        "  for e in range(len(alph_S)):\n",
        "    rems.append(alph_S[e])\n",
        "\n",
        "  words = [x for x in list if (x not in rems)]\n",
        "\n",
        "  return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5w_PCwLwKUi"
      },
      "source": [
        "mention_from=[]\n",
        "mention_message=[]\n",
        "mention_to=[]\n",
        "for i in range(len(df)):\n",
        "  if str(df.iloc[i]['text']).startswith('RT'):\n",
        "    try:\n",
        "      text=df.iloc[i]['text']\n",
        "      result = re.findall(\"(?<![@\\w])@(\\w{1,25})\", text)\n",
        "      if result[0]:\n",
        "        try:\n",
        "          mention_from.append(df.iloc[i]['user_name'])#user_name=screen_name\n",
        "          mention_message.append(text)\n",
        "          mention_to.append(result[0]) #RTの場合、本質的にRTされたツイートを保持するユーザーとのリンクを考える\n",
        "          #mention_to.append(''.join(result)) #メンションの場合はこれだけでOK ⇨ 文中のメンション及び＠から始まる反応を取れていない（が普通に文中に＠を使うような絵文字等が出てくるとできない）\n",
        "        except:\n",
        "          pass\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX05dmHOAK7B"
      },
      "source": [
        "df_rt=pd.DataFrame({'from': mention_from, 'to': mention_to, 'message': mention_message})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1xHMYloPLFe"
      },
      "source": [
        "#コロナ関連のツイートに関するRTネットワーク\n",
        "covid_num=[]\n",
        "for i in range(len(df_rt)):\n",
        "  text=df_rt.iloc[i]['message']\n",
        "  word_list=list(tagger.parse(text).split())\n",
        "  if len([word for word in word_list if word in ['ワクチン']]) !=0:\n",
        "    covid_num.append(i)\n",
        "\n",
        "df_covid=df_rt.iloc[covid_num]\n",
        "df_covid=df_covid.reset_index(drop=True)\n",
        "len(df_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ6UXPt50_An"
      },
      "source": [
        "#networkx: https://networkx.org/documentation/stable//reference/drawing.html\n",
        "import time\n",
        "import networkx as nx\n",
        "G=nx.Graph()\n",
        "for i in range(len(df_covid)):\n",
        "    from_user=df_covid.iloc[i]['from']\n",
        "    to_user=df_covid.iloc[i]['to']\n",
        "    G.add_edge(from_user, to_user, weight = 1)\n",
        "#d=1のものを除去\n",
        "#https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.remove_node.html\n",
        "#2以上を取る手法はこれ：http://faculty.washington.edu/kstarbi/examining-trolls-polarization.pdf\n",
        "for n, d in list(G.degree()):\n",
        "  if d<=2:\n",
        "    G.remove_node(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j0dWI2V2uKj"
      },
      "source": [
        "nx.write_gml(G,'/content/drive/My Drive/Tweet/gml/220110_vaccine_RT_dgt2.gml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gMvuXfBz24H"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "G = nx.read_gml('/content/drive/My Drive/Tweet/gml/220110_vaccine_RT_dgt2.gml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II6hv83Oqeo4"
      },
      "source": [
        "#RTネットワークの大きいものを分析\n",
        "Gcc = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "G0 = G.subgraph(Gcc[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qQ3plf8rkDX"
      },
      "source": [
        "#two=community.kernighan_lin_bisection(G0)\n",
        "#参考: https://networkx.org/documentation/stable/reference/algorithms/community.html\n",
        "from networkx.algorithms import community\n",
        "comp=community.centrality.girvan_newman(G0)\n",
        "#two=community.kernighan_lin_bisection(G0)\n",
        "two=list(sorted(c) for c in next(comp))\n",
        "cluster_number=[]\n",
        "for node in G0.nodes():\n",
        "  for i in range(len(two)):\n",
        "    if node in two[i]:\n",
        "      cluster_number.append(i)\n",
        "\n",
        "#d = dict(zip(G0.nodes(), cluster_number))\n",
        "#nx.set_node_attributes(G0, name='cluster', values=d)\n",
        "#nx.write_gml(G0,'/content/drive/MyDrive/Income_prediction/0420_network/modularity_over2degree_corona_negpos_rt_network.gml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Air0RENSYwlA"
      },
      "source": [
        "d = dict(zip(G0.nodes(), cluster_number))\n",
        "nx.set_node_attributes(G0, name='cluster', values=d)\n",
        "nx.write_gml(G0,'/content/drive/My Drive/Tweet/gml/211227_vaccine_clustered_dgt3.gml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bgRHj0Mrsog"
      },
      "source": [
        "c = collections.Counter(cluster_number)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGv3tRnJ1ZYg"
      },
      "source": [
        "#propagationによるcommunityの特定\n",
        "#参考：https://www.programmersought.com/article/19431905738/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqqtSHEBlc9C"
      },
      "source": [
        "from networkx.algorithms import community\n",
        "communities_generator = list(community.label_propagation_communities(G))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJATEol__cMg"
      },
      "source": [
        "from networkx.algorithms import community\n",
        "def label_propagation_community(G):\n",
        "    communities_generator = list(community.label_propagation_communities(G))\n",
        "    m = []\n",
        "    for i in communities_generator:\n",
        "        m.append(list(i))\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEBxOOBzDNRg"
      },
      "source": [
        "g=label_propagation_community(G)\n",
        "\n",
        "cluster_number=[]\n",
        "for node in G.nodes():\n",
        "  for i in range(len(g)):\n",
        "    if node in g[i]:\n",
        "      cluster_number.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_slbteR9E6hO"
      },
      "source": [
        "max=0\n",
        "max_number=0\n",
        "for i in range(len(g)):\n",
        "  if len(g[i])>max:\n",
        "    max=len(g[i])\n",
        "    max_number=i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbM5cPUkmQoB"
      },
      "source": [
        "d = dict(zip(G.nodes(), cluster_number))\n",
        "nx.set_node_attributes(G, name='cluster', values=d)\n",
        "nx.write_gml(G,'/content/drive/My Drive/Tweet/gml/220110_vactine_propagation_RT_dgt2.gml')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}